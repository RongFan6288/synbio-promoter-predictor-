# real_promoter_predictor.py - ç”¨çœŸå®å¯åŠ¨å­æ•°æ®è®­ç»ƒæ¨¡å‹

import torch
import torch.nn as nn
import matplotlib.pyplot as plt
import pandas as pd
import os

# ----------------------------
# 1. å·¥å…·å‡½æ•°
# ----------------------------
def dna_to_onehot(seq):
    mapping = {'A': [1,0,0,0], 'T': [0,1,0,0], 'C': [0,0,1,0], 'G': [0,0,0,1]}
    return [mapping.get(base.upper(), [0,0,0,0]) for base in seq]

class PromoterCNN(nn.Module):
    def __init__(self, seq_len=20):
        super().__init__()
        self.conv1 = nn.Conv1d(4, 16, kernel_size=4)
        self.relu = nn.ReLU()
        self.pool = nn.MaxPool1d(2)
        self.flatten = nn.Flatten()
        self.fc1 = nn.Linear(16 * ((seq_len - 3) // 2), 32)
        self.fc2 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.conv1(x)
        x = self.relu(x)
        x = self.pool(x)
        x = self.flatten(x)
        x = self.relu(self.fc1(x))
        x = self.sigmoid(self.fc2(x))
        return x.squeeze()

# ----------------------------
# 2. åŠ è½½çœŸå®æ•°æ®
# ----------------------------
def load_real_data(csv_path="ecoli_promoters.csv"):
    df = pd.read_csv(csv_path)
    sequences = []
    labels = []
    
    for _, row in df.iterrows():
        seq = row['sequence']
        label = row['label']
        if len(seq) == 20:  # ç¡®ä¿é•¿åº¦ä¸€è‡´
            sequences.append(dna_to_onehot(seq))
            labels.append(float(label))
    
    X = torch.tensor(sequences, dtype=torch.float32).permute(0, 2, 1)
    y = torch.tensor(labels, dtype=torch.float32)
    return X, y

# ----------------------------
# 3. è®­ç»ƒ & é¢„æµ‹
# ----------------------------
def predict_new_sequence(model, seq):
    """é¢„æµ‹æ–°åºåˆ—æ˜¯å¦ä¸ºå¯åŠ¨å­"""
    if len(seq) != 20:
        raise ValueError("åºåˆ—å¿…é¡»ä¸º20bpï¼")
    onehot = torch.tensor(dna_to_onehot(seq), dtype=torch.float32)
    onehot = onehot.permute(1, 0).unsqueeze(0)  # (1, 4, 20)
    model.eval()
    with torch.no_grad():
        prob = model(onehot).item()
    return prob

def main():
    # å®‰è£…æ£€æŸ¥
    try:
        import pandas
    except ImportError:
        print("âŒ ç¼ºå°‘ pandasï¼è¿è¡Œï¼špip install pandas")
        return

    # åŠ è½½æ•°æ®
    X, y = load_real_data()
    print(f"âœ… åŠ è½½ {len(X)} æ¡çœŸå®å¯åŠ¨å­æ•°æ®")

    # è®­ç»ƒæ¨¡å‹
    model = PromoterCNN(seq_len=20)
    criterion = nn.BCELoss()  # äºŒåˆ†ç±»ç”¨ BCE
    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)

    losses = []
    for epoch in range(100):
        model.train()
        optimizer.zero_grad()
        outputs = model(X)
        loss = criterion(outputs, y)
        loss.backward()
        optimizer.step()
        losses.append(loss.item())

    # ç”» loss æ›²çº¿
    plt.figure(figsize=(8, 4))
    plt.plot(losses)
    plt.title("Training Loss (Real Promoter Data)")
    plt.xlabel("Epoch")
    plt.ylabel("Binary Cross-Entropy Loss")
    plt.savefig("real_training_loss.png", dpi=150)
    plt.close()

    # é¢„æµ‹æ–°åºåˆ—
    test_seq = "TTGACAATATAATGTATTTC"  # å·²çŸ¥å¼ºå¯åŠ¨å­
    prob = predict_new_sequence(model, test_seq)
    print(f"\nğŸ” é¢„æµ‹åºåˆ—: {test_seq}")
    print(f"   å¯åŠ¨å­æ¦‚ç‡: {prob:.2%}")

    # å†è¯•ä¸€ä¸ªéšæœºåºåˆ—
    random_seq = "ATGCATGCATGCATGCATGC"
    prob2 = predict_new_sequence(model, random_seq)
    print(f"\nğŸ” é¢„æµ‹åºåˆ—: {random_seq}")
    print(f"   å¯åŠ¨å­æ¦‚ç‡: {prob2:.2%}")

    print("\nâœ… æ¨¡å‹è®­ç»ƒå®Œæˆï¼å›¾è¡¨å·²ä¿å­˜ä¸º 'real_training_loss.png'")

if __name__ == "__main__":
    main()