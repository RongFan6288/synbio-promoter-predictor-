# promoter_predictor.py - å¯åŠ¨å­æ´»æ€§é¢„æµ‹æ¨¡å‹ï¼ˆCNN + å¯è§†åŒ–ï¼‰

import torch
import torch.nn as nn
import matplotlib.pyplot as plt
import random
import os

# ----------------------------
# 1. DNA åºåˆ—ç¼–ç å·¥å…·
# ----------------------------
def dna_to_onehot(seq):
    """å°†DNAåºåˆ—è½¬ä¸º one-hot ç¼–ç  (A=0, T=1, C=2, G=3)"""
    mapping = {'A': [1,0,0,0], 'T': [0,1,0,0], 'C': [0,0,1,0], 'G': [0,0,0,1]}
    return [mapping.get(base.upper(), [0,0,0,0]) for base in seq]

def generate_promoter_data(n_samples=1000, seq_len=50):
    """ç”Ÿæˆæ¨¡æ‹Ÿå¯åŠ¨å­æ•°æ®ï¼ˆå«TATA boxçš„åºåˆ—æ´»æ€§æ›´é«˜ï¼‰"""
    sequences = []
    labels = []
    bases = "ATCG"
    
    for _ in range(n_samples):
        # éšæœºç”Ÿæˆåºåˆ—
        seq = ''.join(random.choices(bases, k=seq_len))
        
        # å¦‚æœåŒ…å« "TATA"ï¼Œåˆ™æ ‡ç­¾é«˜ï¼ˆæ´»æ€§å¼ºï¼‰
        if "TATA" in seq:
            label = random.uniform(0.7, 1.0)  # é«˜æ´»æ€§
        else:
            label = random.uniform(0.0, 0.3)  # ä½æ´»æ€§
        
        sequences.append(dna_to_onehot(seq))
        labels.append(label)
    
    return torch.tensor(sequences, dtype=torch.float32), \
           torch.tensor(labels, dtype=torch.float32)

# ----------------------------
# 2. CNN æ¨¡å‹å®šä¹‰
# ----------------------------
class PromoterCNN(nn.Module):
    def __init__(self, seq_len=50):
        super().__init__()
        self.conv1 = nn.Conv1d(in_channels=4, out_channels=16, kernel_size=5)
        self.relu = nn.ReLU()
        self.pool = nn.MaxPool1d(2)
        self.flatten = nn.Flatten()
        self.fc1 = nn.Linear(16 * ((seq_len - 4) // 2), 32)
        self.fc2 = nn.Linear(32, 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        # x shape: (batch, 4, seq_len)
        x = self.conv1(x)
        x = self.relu(x)
        x = self.pool(x)
        x = self.flatten(x)
        x = self.relu(self.fc1(x))
        x = self.sigmoid(self.fc2(x))
        return x.squeeze()

# ----------------------------
# 3. è®­ç»ƒå‡½æ•°
# ----------------------------
def train_model():
    # è¶…å‚æ•°
    SEQ_LEN = 50
    BATCH_SIZE = 32
    EPOCHS = 50
    LR = 0.001

    # ç”Ÿæˆæ•°æ®
    X, y = generate_promoter_data(n_samples=1000, seq_len=SEQ_LEN)
    X = X.permute(0, 2, 1)  # è½¬ä¸º (batch, channels=4, seq_len)

    # åˆ›å»ºæ¨¡å‹
    model = PromoterCNN(seq_len=SEQ_LEN)
    criterion = nn.MSELoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=LR)

    # è®­ç»ƒå¾ªç¯
    losses = []
    for epoch in range(EPOCHS):
        model.train()
        total_loss = 0.0
        
        for i in range(0, len(X), BATCH_SIZE):
            batch_x = X[i:i+BATCH_SIZE]
            batch_y = y[i:i+BATCH_SIZE]
            
            optimizer.zero_grad()
            outputs = model(batch_x)
            loss = criterion(outputs, batch_y)
            loss.backward()
            optimizer.step()
            
            total_loss += loss.item()
        
        avg_loss = total_loss / (len(X) // BATCH_SIZE)
        losses.append(avg_loss)
        
        if (epoch + 1) % 10 == 0:
            print(f"Epoch [{epoch+1}/{EPOCHS}], Loss: {avg_loss:.4f}")

    # ä¿å­˜æŸå¤±æ›²çº¿å›¾
    plt.figure(figsize=(8, 5))
    plt.plot(losses, label='Training Loss')
    plt.xlabel('Epoch')
    plt.ylabel('MSE Loss')
    plt.title('Promoter Activity Prediction - Training Loss')
    plt.legend()
    plt.grid(True)
    plt.savefig('training_loss.png', dpi=150, bbox_inches='tight')
    plt.close()

    print("\nâœ… è®­ç»ƒå®Œæˆï¼æŸå¤±æ›²çº¿å·²ä¿å­˜ä¸º 'training_loss.png'")
    print("ğŸ’¡ æç¤ºï¼šåœ¨ VS Code å·¦ä¾§ç‚¹å‡»è¯¥æ–‡ä»¶å³å¯é¢„è§ˆå›¾è¡¨ï¼")

# ----------------------------
# 4. ä¸»ç¨‹åºå…¥å£
# ----------------------------
if __name__ == "__main__":
    # æ£€æŸ¥æ˜¯å¦å®‰è£…äº†å¿…è¦åº“
    try:
        import torch
        import matplotlib
    except ImportError as e:
        print("âŒ ç¼ºå°‘ä¾èµ–åº“ï¼è¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…ï¼š")
        print("pip install torch matplotlib")
        exit(1)
    
    train_model()